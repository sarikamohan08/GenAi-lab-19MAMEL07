{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport os\nimport glob\nimport pandas as pd\nimport random\nimport numpy as np\nimport cv2\nimport base64\nimport imageio\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torch.utils.data as data_utils\nfrom copy import deepcopy\nfrom torch.autograd import Variable\nfrom tqdm import tqdm\nfrom pprint import pprint\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split\nimport os\n\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nprint('Training on',DEVICE)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-08-30T03:53:20.872939Z","iopub.execute_input":"2023-08-30T03:53:20.873267Z","iopub.status.idle":"2023-08-30T03:53:25.190310Z","shell.execute_reply.started":"2023-08-30T03:53:20.873216Z","shell.execute_reply":"2023-08-30T03:53:25.189252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DATASET_PATH =\"/kaggle/input/lfw-dataset/lfw-deepfunneled/lfw-deepfunneled/\"\nATTRIBUTES_PATH = \"/kaggle/input/lfw-attributes/lfw_attributes.txt\"","metadata":{"execution":{"iopub.status.busy":"2023-08-30T03:53:25.193363Z","iopub.execute_input":"2023-08-30T03:53:25.193808Z","iopub.status.idle":"2023-08-30T03:53:25.201200Z","shell.execute_reply.started":"2023-08-30T03:53:25.193727Z","shell.execute_reply":"2023-08-30T03:53:25.200002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Explore the data","metadata":{}},{"cell_type":"code","source":"dataset = []\nfor path in glob.iglob(os.path.join(DATASET_PATH, \"**\", \"*.jpg\")):\n    person = path.split(\"/\")[-2]\n    dataset.append({\"person\":person, \"path\": path})\n    \ndataset = pd.DataFrame(dataset)\n#too much Bush\ndataset = dataset.groupby(\"person\").filter(lambda x: len(x) < 25 )\ndataset.head(10)","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","execution":{"iopub.status.busy":"2023-08-30T03:53:25.203295Z","iopub.execute_input":"2023-08-30T03:53:25.203822Z","iopub.status.idle":"2023-08-30T03:54:09.571444Z","shell.execute_reply.started":"2023-08-30T03:53:25.203738Z","shell.execute_reply":"2023-08-30T03:54:09.569351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset.groupby(\"person\").count()[:200].plot(kind='bar', figsize=(20,5))","metadata":{"execution":{"iopub.status.busy":"2023-08-30T03:54:09.572956Z","iopub.execute_input":"2023-08-30T03:54:09.573238Z","iopub.status.idle":"2023-08-30T03:54:12.976994Z","shell.execute_reply.started":"2023-08-30T03:54:09.573190Z","shell.execute_reply":"2023-08-30T03:54:12.975845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20,10))\nfor i in range(20):\n    idx = random.randint(0, len(dataset))\n    img = plt.imread(dataset.path.iloc[idx])\n    plt.subplot(4, 5, i+1)\n    plt.imshow(img)\n    plt.title(dataset.person.iloc[idx])\n    plt.xticks([])\n    plt.yticks([])\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-30T03:54:12.980395Z","iopub.execute_input":"2023-08-30T03:54:12.980759Z","iopub.status.idle":"2023-08-30T03:54:14.911243Z","shell.execute_reply.started":"2023-08-30T03:54:12.980699Z","shell.execute_reply":"2023-08-30T03:54:14.910383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prepare the dataset","metadata":{}},{"cell_type":"code","source":"def fetch_dataset(dx=80,dy=80, dimx=45,dimy=45):\n    \n    df_attrs = pd.read_csv(ATTRIBUTES_PATH, sep='\\t', skiprows=1,) \n    df_attrs = pd.DataFrame(df_attrs.iloc[:,:-1].values, columns = df_attrs.columns[1:])\n    \n    photo_ids = []\n    for dirpath, dirnames, filenames in os.walk(DATASET_PATH):\n        for fname in filenames:\n            if fname.endswith(\".jpg\"):\n                fpath = os.path.join(dirpath,fname)\n                photo_id = fname[:-4].replace('_',' ').split()\n                person_id = ' '.join(photo_id[:-1])\n                photo_number = int(photo_id[-1])\n                photo_ids.append({'person':person_id,'imagenum':photo_number,'photo_path':fpath})\n\n    photo_ids = pd.DataFrame(photo_ids)\n    df = pd.merge(df_attrs,photo_ids,on=('person','imagenum'))\n\n    assert len(df)==len(df_attrs),\"lost some data when merging dataframes\"\n    \n    all_photos = df['photo_path'].apply(imageio.imread)\\\n                                .apply(lambda img:img[dy:-dy,dx:-dx])\\\n                                .apply(lambda img: np.array(Image.fromarray(img).resize([dimx,dimy])) )\n\n    all_photos = np.stack(all_photos.values).astype('uint8')\n    all_attrs = df.drop([\"photo_path\",\"person\",\"imagenum\"],axis=1)\n    \n    return all_photos,all_attrs","metadata":{"execution":{"iopub.status.busy":"2023-08-30T03:54:14.913863Z","iopub.execute_input":"2023-08-30T03:54:14.914335Z","iopub.status.idle":"2023-08-30T03:54:14.927771Z","shell.execute_reply.started":"2023-08-30T03:54:14.914264Z","shell.execute_reply":"2023-08-30T03:54:14.926533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data, attrs = fetch_dataset()","metadata":{"execution":{"iopub.status.busy":"2023-08-30T03:54:14.929612Z","iopub.execute_input":"2023-08-30T03:54:14.930007Z","iopub.status.idle":"2023-08-30T03:56:02.137363Z","shell.execute_reply.started":"2023-08-30T03:54:14.929944Z","shell.execute_reply":"2023-08-30T03:56:02.136254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#45,45\nIMAGE_H = data.shape[1]\nIMAGE_W = data.shape[2]\n\nN_CHANNELS = 3","metadata":{"execution":{"iopub.status.busy":"2023-08-30T03:56:02.139167Z","iopub.execute_input":"2023-08-30T03:56:02.139459Z","iopub.status.idle":"2023-08-30T03:56:02.144579Z","shell.execute_reply.started":"2023-08-30T03:56:02.139413Z","shell.execute_reply":"2023-08-30T03:56:02.143315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = np.array(data / 255, dtype='float32')\nX_train, X_val = train_test_split(data, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T03:56:02.146302Z","iopub.execute_input":"2023-08-30T03:56:02.146768Z","iopub.status.idle":"2023-08-30T03:56:02.689983Z","shell.execute_reply.started":"2023-08-30T03:56:02.146693Z","shell.execute_reply":"2023-08-30T03:56:02.689078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = torch.FloatTensor(X_train)\nX_val = torch.FloatTensor(X_val)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T03:56:02.691436Z","iopub.execute_input":"2023-08-30T03:56:02.691723Z","iopub.status.idle":"2023-08-30T03:56:02.700468Z","shell.execute_reply.started":"2023-08-30T03:56:02.691676Z","shell.execute_reply":"2023-08-30T03:56:02.699479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Building simple autoencoder","metadata":{}},{"cell_type":"code","source":"dim_z=100","metadata":{"execution":{"iopub.status.busy":"2023-08-30T03:56:02.702079Z","iopub.execute_input":"2023-08-30T03:56:02.702457Z","iopub.status.idle":"2023-08-30T03:56:02.713582Z","shell.execute_reply.started":"2023-08-30T03:56:02.702385Z","shell.execute_reply":"2023-08-30T03:56:02.712519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.shape","metadata":{"execution":{"iopub.status.busy":"2023-08-30T03:56:02.715076Z","iopub.execute_input":"2023-08-30T03:56:02.715356Z","iopub.status.idle":"2023-08-30T03:56:02.728285Z","shell.execute_reply.started":"2023-08-30T03:56:02.715307Z","shell.execute_reply":"2023-08-30T03:56:02.727176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Autoencoder(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.encoder = nn.Sequential(\n            nn.Linear(45*45*3,1500),\n            nn.BatchNorm1d(1500),\n            nn.ReLU(),\n            nn.Linear(1500,1000),\n            nn.BatchNorm1d(1000),\n            nn.ReLU(),\n            nn.Linear(1000, dim_z),\n            nn.BatchNorm1d(dim_z),\n            nn.ReLU()\n        )\n        self.decoder = nn.Sequential(\n            nn.Linear(dim_z,1000),\n            nn.BatchNorm1d(1000),\n            nn.ReLU(),\n            #nn.Linear(500,1000),\n            #nn.ReLU(),\n            nn.Linear(1000,1500),\n            nn.BatchNorm1d(1500),\n            nn.ReLU(),\n            nn.Linear(1500,45*45*3)\n        )\n      \n    def encode(self,x):\n        return self.encoder(x)\n    \n    def decode(self,z):\n        return self.decoder(z)\n        \n    def forward(self, x):\n        encoded = self.encode(x) \n        decoded = self.decode(encoded)     \n\n        \n        return encoded, decoded","metadata":{"execution":{"iopub.status.busy":"2023-08-30T03:56:02.729588Z","iopub.execute_input":"2023-08-30T03:56:02.729926Z","iopub.status.idle":"2023-08-30T03:56:02.743025Z","shell.execute_reply.started":"2023-08-30T03:56:02.729874Z","shell.execute_reply":"2023-08-30T03:56:02.742050Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Autoencoder_cnn(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.encoder = nn.Sequential(\n            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2),\n            nn.Conv2d(in_channels=16, out_channels=8, kernel_size=3),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2),\n        )\n        self.decoder = nn.Sequential(\n            nn.ConvTranspose2d(in_channels=8, out_channels=16, kernel_size=5, stride=2),\n            nn.ReLU(),\n            nn.ConvTranspose2d(in_channels=16, out_channels=3, kernel_size=5, stride=2),\n            #nn.ReLU(),\n            #nn.ConvTranspose2d(in_channels=8, out_channels=8, kernel_size=3, stride=2),\n            #nn.ReLU(),\n            #nn.ConvTranspose2d(in_channels=8, out_channels=3, kernel_size=5, stride=2)\n        )\n        \n    def decode(self,z):\n        return self.decoder(z)\n        \n    def forward(self, x):\n        x = x.permute(0,3,1,2)\n        encoded = self.encoder(x)  \n        decoded = self.decode(encoded)     \n\n        \n        return encoded, decoded","metadata":{"execution":{"iopub.status.busy":"2023-08-30T03:56:02.746537Z","iopub.execute_input":"2023-08-30T03:56:02.746918Z","iopub.status.idle":"2023-08-30T03:56:02.763216Z","shell.execute_reply.started":"2023-08-30T03:56:02.746867Z","shell.execute_reply":"2023-08-30T03:56:02.762306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_auto = Autoencoder().to(DEVICE)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T03:56:02.764991Z","iopub.execute_input":"2023-08-30T03:56:02.765596Z","iopub.status.idle":"2023-08-30T03:56:02.940649Z","shell.execute_reply.started":"2023-08-30T03:56:02.765319Z","shell.execute_reply":"2023-08-30T03:56:02.939660Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train autoencoder","metadata":{}},{"cell_type":"code","source":"def get_batch(data, batch_size=64):\n    total_len = data.shape[0]\n    for i in range(0, total_len, batch_size):\n        yield data[i:min(i+batch_size,total_len)]\n\ndef plot_gallery(images, h, w, n_row=3, n_col=6, with_title=False, titles=[]):\n    plt.figure(figsize=(1.5 * n_col, 1.7 * n_row))\n    plt.subplots_adjust(bottom=0, left=.01, right=.99, top=.90, hspace=.35)\n    for i in range(n_row * n_col):\n        plt.subplot(n_row, n_col, i + 1)\n        try:\n            plt.imshow(images[i].reshape((h, w, 3)), cmap=plt.cm.gray, vmin=-1, vmax=1, interpolation='nearest')\n            if with_title:\n                plt.title(titles[i])\n            plt.xticks(())\n            plt.yticks(())\n        except:\n            pass\n        \ndef fit_epoch(model, train_x, criterion, optimizer, batch_size, is_cnn=False):\n    running_loss = 0.0\n    processed_data = 0\n    \n    for inputs in get_batch(train_x,batch_size):\n        \n        if not is_cnn:\n            inputs = inputs.view(-1, 45*45*3)\n        inputs = inputs.to(DEVICE)\n        \n        optimizer.zero_grad()\n        \n        encoder, decoder = model(inputs)\n        \n        #print('decoder shape: ', decoder.shape)\n        \n        if not is_cnn:\n            outputs = decoder.view(-1, 45*45*3)\n        else:\n            outputs = decoder.permute(0,2,3,1)\n        \n        loss = criterion(outputs,inputs)\n        loss.backward()\n        optimizer.step()\n        \n        running_loss += loss.item() * inputs.shape[0]\n        processed_data += inputs.shape[0]\n    \n    train_loss = running_loss / processed_data    \n    return train_loss\n\ndef eval_epoch(model, x_val, criterion, is_cnn=False):\n    running_loss = 0.0\n    processed_data = 0\n    model.eval()\n    \n    for inputs in get_batch(x_val):\n        if not is_cnn:\n            inputs = inputs.view(-1, 45*45*3)\n        inputs = inputs.to(DEVICE)\n        \n        with torch.set_grad_enabled(False):\n            encoder, decoder = model(inputs)\n            \n            if not is_cnn:\n                outputs = decoder.view(-1, 45*45*3)\n            else:\n                outputs = decoder.permute(0,2,3,1)\n                \n            loss = criterion(outputs,inputs)\n            running_loss += loss.item() * inputs.shape[0]\n            processed_data += inputs.shape[0]\n    \n    val_loss = running_loss / processed_data\n    \n    #draw\n    with torch.set_grad_enabled(False):\n        pic = x_val[3]\n        \n        if not is_cnn:            \n            pic_input = pic.view(-1, 45*45*3)\n        else:\n            pic_input = torch.FloatTensor(pic.unsqueeze(0))\n            \n        pic_input = pic_input.to(DEVICE)        \n        encoder, decoder = model(pic_input)\n        \n        if not is_cnn:\n            pic_output = decoder.view(-1, 45*45*3).squeeze()\n        else:\n            pic_output = decoder.permute(0,2,3,1)\n            \n        pic_output = pic_output.to(\"cpu\")        \n        pic_input = pic_input.to(\"cpu\")\n        plot_gallery([pic_input, pic_output],45,45,1,2)\n    \n    return val_loss\n\ndef train(train_x, val_x, model, epochs=10, batch_size=32, is_cnn=False):     \n    criterion = nn.MSELoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)        \n    history = []\n    log_template = \"\\nEpoch {ep:03d} train_loss: {t_loss:0.4f} val_loss: {val_loss:0.4f}\"\n    \n    with tqdm(desc=\"epoch\", total=epochs) as pbar_outer:\n        for epoch in range(epochs):            \n            train_loss = fit_epoch(model,train_x,criterion,optimizer,batch_size,is_cnn)\n            val_loss = eval_epoch(model,val_x,criterion, is_cnn)\n            print(\"loss: \", train_loss)\n\n            history.append((train_loss,val_loss))\n\n            pbar_outer.update(1)\n            tqdm.write(log_template.format(ep=epoch+1, t_loss=train_loss, val_loss=val_loss))            \n        \n    return history","metadata":{"execution":{"iopub.status.busy":"2023-08-30T03:56:02.942121Z","iopub.execute_input":"2023-08-30T03:56:02.942406Z","iopub.status.idle":"2023-08-30T03:56:02.971169Z","shell.execute_reply.started":"2023-08-30T03:56:02.942359Z","shell.execute_reply":"2023-08-30T03:56:02.970229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = train(X_train, X_val, model_auto, epochs=50, batch_size=64)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T03:56:02.972820Z","iopub.execute_input":"2023-08-30T03:56:02.973172Z","iopub.status.idle":"2023-08-30T04:36:21.861322Z","shell.execute_reply.started":"2023-08-30T03:56:02.973114Z","shell.execute_reply":"2023-08-30T04:36:21.860228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loss, val_loss = zip(*history)\nplt.figure(figsize=(15,10))\nplt.plot(train_loss, label='Train loss')\nplt.plot(val_loss, label='Val loss')\nplt.legend(loc='best')\nplt.xlabel(\"epochs\")\nplt.ylabel(\"loss\")\nplt.plot();","metadata":{"execution":{"iopub.status.busy":"2023-08-30T04:36:21.863131Z","iopub.execute_input":"2023-08-30T04:36:21.863744Z","iopub.status.idle":"2023-08-30T04:36:22.434320Z","shell.execute_reply.started":"2023-08-30T04:36:21.863675Z","shell.execute_reply":"2023-08-30T04:36:22.433295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Sampling","metadata":{}},{"cell_type":"markdown","source":"Let's generate some samples from random vectors","metadata":{}},{"cell_type":"code","source":"z = np.random.randn(25, dim_z)\nprint(z.shape)\n\nwith torch.no_grad():\n    inputs = torch.FloatTensor(z)    \n    inputs = inputs.to(DEVICE)\n    model_auto.eval()\n    output = model_auto.decode(inputs)\n    plot_gallery(output.data.cpu().numpy(), IMAGE_H, IMAGE_W, n_row=5, n_col=5)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T04:36:22.435984Z","iopub.execute_input":"2023-08-30T04:36:22.436563Z","iopub.status.idle":"2023-08-30T04:36:23.485764Z","shell.execute_reply.started":"2023-08-30T04:36:22.436501Z","shell.execute_reply":"2023-08-30T04:36:23.484690Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"attrs.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-30T04:36:23.487499Z","iopub.execute_input":"2023-08-30T04:36:23.488091Z","iopub.status.idle":"2023-08-30T04:36:23.521749Z","shell.execute_reply.started":"2023-08-30T04:36:23.488028Z","shell.execute_reply":"2023-08-30T04:36:23.520858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"attrs.columns","metadata":{"execution":{"iopub.status.busy":"2023-08-30T04:36:23.523420Z","iopub.execute_input":"2023-08-30T04:36:23.523770Z","iopub.status.idle":"2023-08-30T04:36:23.530384Z","shell.execute_reply.started":"2023-08-30T04:36:23.523704Z","shell.execute_reply":"2023-08-30T04:36:23.529358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"smile_ids = attrs['Smiling'].sort_values(ascending=False).iloc[100:125].index.values\nsmile_data = data[smile_ids]\n\nno_smile_ids = attrs['Smiling'].sort_values(ascending=True).head(25).index.values\nno_smile_data = data[no_smile_ids]\n\neyeglasses_ids = attrs['Eyeglasses'].sort_values(ascending=False).head(25).index.values\neyeglasses_data = data[eyeglasses_ids]\n\nsunglasses_ids = attrs['Sunglasses'].sort_values(ascending=False).head(25).index.values\nsunglasses_data = data[sunglasses_ids]","metadata":{"execution":{"iopub.status.busy":"2023-08-30T04:36:23.532000Z","iopub.execute_input":"2023-08-30T04:36:23.532315Z","iopub.status.idle":"2023-08-30T04:36:23.582038Z","shell.execute_reply.started":"2023-08-30T04:36:23.532259Z","shell.execute_reply":"2023-08-30T04:36:23.581212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_gallery(smile_data, IMAGE_H, IMAGE_W, n_row=5, n_col=5, with_title=True, titles=smile_ids)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T04:36:23.583341Z","iopub.execute_input":"2023-08-30T04:36:23.583753Z","iopub.status.idle":"2023-08-30T04:36:24.583845Z","shell.execute_reply.started":"2023-08-30T04:36:23.583711Z","shell.execute_reply":"2023-08-30T04:36:24.582880Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_gallery(no_smile_data, IMAGE_H, IMAGE_W, n_row=5, n_col=5, with_title=True, titles=no_smile_ids)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T04:36:24.585453Z","iopub.execute_input":"2023-08-30T04:36:24.586040Z","iopub.status.idle":"2023-08-30T04:36:25.621228Z","shell.execute_reply.started":"2023-08-30T04:36:24.585976Z","shell.execute_reply":"2023-08-30T04:36:25.620289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Calculating latent space vector for the selected images.","metadata":{}},{"cell_type":"code","source":"def to_latent(pic):\n    with torch.no_grad():\n        inputs = torch.FloatTensor(pic.reshape(-1, 45*45*3))\n        inputs = inputs.to(DEVICE)\n        model_auto.eval()\n        output = model_auto.encode(inputs)        \n        return output\n\ndef from_latent(vec):\n    with torch.no_grad():\n        inputs = vec.to(DEVICE)\n        model_auto.eval()\n        output = model_auto.decode(inputs)        \n        return output","metadata":{"execution":{"iopub.status.busy":"2023-08-30T04:36:27.577906Z","iopub.execute_input":"2023-08-30T04:36:27.578422Z","iopub.status.idle":"2023-08-30T04:36:27.587975Z","shell.execute_reply.started":"2023-08-30T04:36:27.578211Z","shell.execute_reply":"2023-08-30T04:36:27.586665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"smile_latent = to_latent(smile_data).mean(axis=0)\nno_smile_latent = to_latent(no_smile_data).mean(axis=0)\nsunglasses_latent = to_latent(sunglasses_data).mean(axis=0)\n\nsmile_vec = smile_latent-no_smile_latent\nsunglasses_vec = sunglasses_latent - smile_latent\n\ndef make_me_smile(ids):\n    for id in ids:\n        pic = data[id:id+1]\n        latent_vec = to_latent(pic)\n        latent_vec[0] += smile_vec\n        pic_output = from_latent(latent_vec)\n        pic_output = pic_output.view(-1,45,45,3).cpu()\n        plot_gallery([pic,pic_output], IMAGE_H, IMAGE_W, n_row=1, n_col=2)\n        \ndef give_me_sunglasses(ids):\n    for id in ids:\n        pic = data[id:id+1]\n        latent_vec = to_latent(pic)\n        latent_vec[0] += sunglasses_vec\n        pic_output = from_latent(latent_vec)\n        pic_output = pic_output.view(-1,45,45,3).cpu()\n        plot_gallery([pic,pic_output], IMAGE_H, IMAGE_W, n_row=1, n_col=2)\n    ","metadata":{"execution":{"iopub.status.busy":"2023-08-30T04:36:27.589800Z","iopub.execute_input":"2023-08-30T04:36:27.590420Z","iopub.status.idle":"2023-08-30T04:36:27.643902Z","shell.execute_reply.started":"2023-08-30T04:36:27.590172Z","shell.execute_reply":"2023-08-30T04:36:27.642904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"make_me_smile(no_smile_ids)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T04:36:27.645523Z","iopub.execute_input":"2023-08-30T04:36:27.645942Z","iopub.status.idle":"2023-08-30T04:36:30.249996Z","shell.execute_reply.started":"2023-08-30T04:36:27.645856Z","shell.execute_reply":"2023-08-30T04:36:30.248873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dim_z = 256","metadata":{"execution":{"iopub.status.busy":"2023-08-30T04:36:32.337272Z","iopub.execute_input":"2023-08-30T04:36:32.337846Z","iopub.status.idle":"2023-08-30T04:36:32.343206Z","shell.execute_reply.started":"2023-08-30T04:36:32.337619Z","shell.execute_reply":"2023-08-30T04:36:32.342189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class VAE(nn.Module):\n    def __init__(self):\n        super(VAE, self).__init__()\n        self.fc1 = nn.Linear(45*45*3, 1500)\n        self.fc21 = nn.Linear(1500, dim_z)\n        self.fc22 = nn.Linear(1500, dim_z)\n        self.fc3 = nn.Linear(dim_z, 1500)\n        self.fc4 = nn.Linear(1500, 45*45*3)        \n        self.relu = nn.LeakyReLU()\n\n    def encode(self, x):\n        x = self.relu(self.fc1(x))\n        return self.fc21(x), self.fc22(x)\n\n    def reparameterize(self, mu, logvar):\n        std = torch.exp(0.5 *logvar)\n        eps = torch.randn_like(std)\n        return eps.mul(std).add_(mu)\n    \n    def decode(self, z):\n        z = self.relu(self.fc3(z)) #1500\n        return torch.sigmoid(self.fc4(z))\n\n    def forward(self, x):\n        mu, logvar = self.encode(x)\n        z = self.reparameterize(mu, logvar)\n        z = self.decode(z)\n        return z, mu, logvar\n    \ndef loss_vae_fn(x, recon_x, mu, logvar):    \n    BCE = F.binary_cross_entropy(recon_x, x, reduction='sum')\n    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n    return BCE + KLD","metadata":{"execution":{"iopub.status.busy":"2023-08-30T04:36:32.348269Z","iopub.execute_input":"2023-08-30T04:36:32.348911Z","iopub.status.idle":"2023-08-30T04:36:32.561104Z","shell.execute_reply.started":"2023-08-30T04:36:32.348836Z","shell.execute_reply":"2023-08-30T04:36:32.559862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_vae = VAE().to(DEVICE)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T04:36:32.563414Z","iopub.execute_input":"2023-08-30T04:36:32.564041Z","iopub.status.idle":"2023-08-30T04:36:32.749278Z","shell.execute_reply.started":"2023-08-30T04:36:32.563798Z","shell.execute_reply":"2023-08-30T04:36:32.747731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def fit_epoch_vae(model, train_x, optimizer, batch_size, is_cnn=False):\n    running_loss = 0.0\n    processed_data = 0\n    \n    for inputs in get_batch(train_x,batch_size):\n        inputs = inputs.view(-1, 45*45*3)\n        inputs = inputs.to(DEVICE)        \n        optimizer.zero_grad()\n        \n        decoded,mu,logvar, = model(inputs)\n        outputs = decoded.view(-1, 45*45*3)\n        outputs = outputs.to(DEVICE)\n        \n        loss = loss_vae_fn(inputs,outputs,mu,logvar)\n        loss.backward()\n        optimizer.step()\n        \n        running_loss += loss.item() * inputs.shape[0]\n        processed_data += inputs.shape[0]\n    \n    train_loss = running_loss / processed_data    \n    return train_loss\n\ndef eval_epoch_vae(model, x_val, batch_size):\n    running_loss = 0.0\n    processed_data = 0\n    model.eval()\n    \n    for inputs in get_batch(x_val,batch_size=batch_size):\n        inputs = inputs.view(-1, 45*45*3)\n        inputs = inputs.to(DEVICE)\n        \n        with torch.set_grad_enabled(False):\n            decoded,mu,logvar = model(inputs)\n            outputs = decoded.view(-1, 45*45*3)        \n            loss = loss_vae_fn(inputs,outputs,mu,logvar)\n            running_loss += loss.item() * inputs.shape[0]\n            processed_data += inputs.shape[0]\n    \n    val_loss = running_loss / processed_data\n    \n    #draw\n    with torch.set_grad_enabled(False):\n        pic = x_val[3]         \n        pic_input = pic.view(-1, 45*45*3)            \n        pic_input = pic_input.to(DEVICE)        \n        decoded,mu,logvar = model(inputs)        \n        pic_output = decoded[0].view(-1, 45*45*3).squeeze()\n        pic_output = pic_output.to(\"cpu\") \n        pic_input = pic_input.to(\"cpu\")\n        plot_gallery([pic_input, pic_output],45,45,1,2)\n    \n    return val_loss\n\ndef train_vae(train_x, val_x, model, epochs=10, batch_size=32, lr=0.001):\n    optimizer = torch.optim.Adam(model.parameters(), lr=lr)        \n    history = []\n    log_template = \"\\nEpoch {ep:03d} train_loss: {t_loss:0.4f} val_loss: {val_loss:0.4f}\"\n    \n    with tqdm(desc=\"epoch\", total=epochs) as pbar_outer:\n        for epoch in range(epochs):            \n            train_loss = fit_epoch_vae(model,train_x,optimizer,batch_size)\n            val_loss = eval_epoch_vae(model,val_x,batch_size)\n            print(\"loss: \", train_loss)\n\n            history.append((train_loss,val_loss))\n\n            pbar_outer.update(1)\n            tqdm.write(log_template.format(ep=epoch+1, t_loss=train_loss, val_loss=val_loss))            \n        \n    return history","metadata":{"execution":{"iopub.status.busy":"2023-08-30T04:36:32.751342Z","iopub.execute_input":"2023-08-30T04:36:32.751797Z","iopub.status.idle":"2023-08-30T04:36:32.773098Z","shell.execute_reply.started":"2023-08-30T04:36:32.751712Z","shell.execute_reply":"2023-08-30T04:36:32.772029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_vae = train_vae(X_train, X_val, model_vae, epochs=50, batch_size=128, lr=0.001)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T04:36:32.774908Z","iopub.execute_input":"2023-08-30T04:36:32.775347Z","iopub.status.idle":"2023-08-30T04:58:19.367205Z","shell.execute_reply.started":"2023-08-30T04:36:32.775257Z","shell.execute_reply":"2023-08-30T04:58:19.366231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loss, val_loss = zip(*history_vae)\nplt.figure(figsize=(15,10))\nplt.plot(train_loss, label='Train loss')\nplt.plot(val_loss, label='Val loss')\nplt.legend(loc='best')\nplt.xlabel(\"epochs\")\nplt.ylabel(\"loss\")\nplt.plot();","metadata":{"execution":{"iopub.status.busy":"2023-08-30T04:58:19.368835Z","iopub.execute_input":"2023-08-30T04:58:19.369561Z","iopub.status.idle":"2023-08-30T04:58:19.639451Z","shell.execute_reply.started":"2023-08-30T04:58:19.369166Z","shell.execute_reply":"2023-08-30T04:58:19.638498Z"},"trusted":true},"execution_count":null,"outputs":[]}]}